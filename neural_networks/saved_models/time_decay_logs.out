Running Reinforcement Learning

Running simulations. . .
Number of moves available for training:  240
Number of moves available for testing:  61

Training. . .
Epoch:  0
Training Loss: 277.2136650085449 and Testing Loss: 96.06007766723633
Epoch:  1
Training Loss: 299.19405364990234 and Testing Loss: 95.37048721313477
Epoch:  2
Training Loss: 290.06836128234863 and Testing Loss: 93.94208526611328
Epoch:  3
Training Loss: 278.19937324523926 and Testing Loss: 91.73648452758789
Epoch:  4
Training Loss: 277.17768573760986 and Testing Loss: 88.43070220947266

Evaluating players at checkpoint: 0 with time threshold: 0.5

Number of trained player wins: 11
Number of previous best player wins: 31
Number of ties: 8
Trained player win percentage:  0.2619047619047619
Using the previous best player.

Running simulations. . .
Number of moves available for training:  482
Number of moves available for testing:  121

Training. . .
Epoch:  0
Training Loss: 679.0729217529297 and Testing Loss: 128.83960151672363
Epoch:  1
Training Loss: 674.1803684234619 and Testing Loss: 119.75617408752441
Epoch:  2
Training Loss: 555.2229113578796 and Testing Loss: 111.49208450317383
Epoch:  3
Training Loss: 542.7883801460266 and Testing Loss: 113.9955940246582
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 1 with time threshold: 0.5

Number of trained player wins: 4
Number of previous best player wins: 34
Number of ties: 12
Trained player win percentage:  0.10526315789473684
Using the previous best player.

Running simulations. . .
Number of moves available for training:  722
Number of moves available for testing:  181

Training. . .
Epoch:  0
Training Loss: 864.5886611938477 and Testing Loss: 210.66924667358398
Epoch:  1
Training Loss: 854.3037586212158 and Testing Loss: 198.42510986328125
Epoch:  2
Training Loss: 788.7538909912109 and Testing Loss: 184.11124420166016
Epoch:  3
Training Loss: 786.6053657531738 and Testing Loss: 194.05816650390625
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 2 with time threshold: 0.5

Number of trained player wins: 11
Number of previous best player wins: 2
Number of ties: 37
Trained player win percentage:  0.8461538461538461
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 772.2136616706848 and Testing Loss: 207.94346237182617
Epoch:  1
Training Loss: 777.9359264373779 and Testing Loss: 234.09755420684814
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 3 with time threshold: 0.5

Number of trained player wins: 22
Number of previous best player wins: 10
Number of ties: 18
Trained player win percentage:  0.6875
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 733.9060468673706 and Testing Loss: 199.46895599365234
Epoch:  1
Training Loss: 766.0226230621338 and Testing Loss: 222.68335437774658
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 4 with time threshold: 0.5

Number of trained player wins: 15
Number of previous best player wins: 11
Number of ties: 24
Trained player win percentage:  0.5769230769230769
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 640.994288444519 and Testing Loss: 194.24896812438965
Epoch:  1
Training Loss: 709.9670572280884 and Testing Loss: 191.2221164703369
Epoch:  2
Training Loss: 651.2393841743469 and Testing Loss: 171.62317085266113
Epoch:  3
Training Loss: 637.3089761734009 and Testing Loss: 197.83405208587646
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 5 with time threshold: 0.5

Number of trained player wins: 16
Number of previous best player wins: 3
Number of ties: 31
Trained player win percentage:  0.8421052631578947
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 654.1539850234985 and Testing Loss: 179.1710557937622
Epoch:  1
Training Loss: 658.4436893463135 and Testing Loss: 148.51051473617554
Epoch:  2
Training Loss: 651.2738223075867 and Testing Loss: 147.56388235092163
Epoch:  3
Training Loss: 645.4878692626953 and Testing Loss: 146.0845227241516
Epoch:  4
Training Loss: 638.7093734741211 and Testing Loss: 156.6850471496582
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 6 with time threshold: 0.5

Number of trained player wins: 11
Number of previous best player wins: 16
Number of ties: 23
Trained player win percentage:  0.4074074074074074
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 630.802975654602 and Testing Loss: 181.9774341583252
Epoch:  1
Training Loss: 631.2841215133667 and Testing Loss: 166.75319480895996
Epoch:  2
Training Loss: 615.9986457824707 and Testing Loss: 162.91817712783813
Epoch:  3
Training Loss: 593.409571647644 and Testing Loss: 171.8043918609619
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 7 with time threshold: 0.5

Number of trained player wins: 7
Number of previous best player wins: 10
Number of ties: 33
Trained player win percentage:  0.4117647058823529
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 649.0098676681519 and Testing Loss: 160.18901872634888
Epoch:  1
Training Loss: 644.5049781799316 and Testing Loss: 153.3677110671997
Epoch:  2
Training Loss: 608.4674320220947 and Testing Loss: 156.65156173706055
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 8 with time threshold: 0.5

Number of trained player wins: 23
Number of previous best player wins: 6
Number of ties: 21
Trained player win percentage:  0.7931034482758621
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 701.5239152908325 and Testing Loss: 176.47512531280518
Epoch:  1
Training Loss: 688.8434152603149 and Testing Loss: 156.86045455932617
Epoch:  2
Training Loss: 657.7816209793091 and Testing Loss: 152.35273933410645
Epoch:  3
Training Loss: 650.7937650680542 and Testing Loss: 138.74028539657593
Epoch:  4
Training Loss: 646.322187423706 and Testing Loss: 148.5655279159546
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 9 with time threshold: 0.5

Number of trained player wins: 15
Number of previous best player wins: 14
Number of ties: 21
Trained player win percentage:  0.5172413793103449
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 723.853458404541 and Testing Loss: 189.35619497299194
Epoch:  1
Training Loss: 696.0697340965271 and Testing Loss: 195.90459442138672
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 10 with time threshold: 0.5

Number of trained player wins: 16
Number of previous best player wins: 10
Number of ties: 24
Trained player win percentage:  0.6153846153846154
Using the trained player.

Comparing performance to older player at index:  0

Number of trained player wins: 6
Number of previous best player wins: 29
Number of ties: 15
Trained player win percentage:  0.17142857142857143

Comparing performance to Pure MCTS

Number of trained player wins: 0
Number of previous best player wins: 29
Number of ties: 21
Trained player win percentage:  0.0

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 674.2249479293823 and Testing Loss: 240.97517490386963
Epoch:  1
Training Loss: 717.6540946960449 and Testing Loss: 192.50701904296875
Epoch:  2
Training Loss: 665.4711894989014 and Testing Loss: 188.02302360534668
Epoch:  3
Training Loss: 656.4591331481934 and Testing Loss: 186.72839641571045
Epoch:  4
Training Loss: 650.4692854881287 and Testing Loss: 207.08511924743652
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 11 with time threshold: 0.45

Number of trained player wins: 4
Number of previous best player wins: 30
Number of ties: 16
Trained player win percentage:  0.11764705882352941
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 658.8388595581055 and Testing Loss: 284.1103057861328
Epoch:  1
Training Loss: 699.0099611282349 and Testing Loss: 238.45425987243652
Epoch:  2
Training Loss: 649.0912494659424 and Testing Loss: 216.91417121887207
Epoch:  3
Training Loss: 640.2401905059814 and Testing Loss: 235.0504264831543
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 12 with time threshold: 0.45

Number of trained player wins: 12
Number of previous best player wins: 19
Number of ties: 19
Trained player win percentage:  0.3870967741935484
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 684.258617401123 and Testing Loss: 233.6307611465454
Epoch:  1
Training Loss: 724.7099342346191 and Testing Loss: 210.83996486663818
Epoch:  2
Training Loss: 675.1178531646729 and Testing Loss: 194.13160705566406
Epoch:  3
Training Loss: 666.0396308898926 and Testing Loss: 205.45188903808594
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 13 with time threshold: 0.45

Number of trained player wins: 19
Number of previous best player wins: 15
Number of ties: 16
Trained player win percentage:  0.5588235294117647
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 681.1041326522827 and Testing Loss: 187.34848594665527
Epoch:  1
Training Loss: 685.3524398803711 and Testing Loss: 188.42858982086182
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 14 with time threshold: 0.45

Number of trained player wins: 14
Number of previous best player wins: 17
Number of ties: 19
Trained player win percentage:  0.45161290322580644
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 667.544994354248 and Testing Loss: 199.3249535560608
Epoch:  1
Training Loss: 668.670654296875 and Testing Loss: 222.15145587921143
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 15 with time threshold: 0.45

Number of trained player wins: 17
Number of previous best player wins: 18
Number of ties: 15
Trained player win percentage:  0.4857142857142857
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 681.6546630859375 and Testing Loss: 187.4432635307312
Epoch:  1
Training Loss: 677.8058347702026 and Testing Loss: 177.20152139663696
Epoch:  2
Training Loss: 612.2687592506409 and Testing Loss: 165.5144443511963
Epoch:  3
Training Loss: 576.5831956863403 and Testing Loss: 162.5351448059082
Epoch:  4
Training Loss: 568.4783048629761 and Testing Loss: 174.80921745300293
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 16 with time threshold: 0.45

Number of trained player wins: 7
Number of previous best player wins: 8
Number of ties: 35
Trained player win percentage:  0.4666666666666667
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 684.8624324798584 and Testing Loss: 204.05308532714844
Epoch:  1
Training Loss: 679.1559896469116 and Testing Loss: 179.38510704040527
Epoch:  2
Training Loss: 608.8885450363159 and Testing Loss: 151.02083539962769
Epoch:  3
Training Loss: 578.7734003067017 and Testing Loss: 168.21661186218262
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 17 with time threshold: 0.45

Number of trained player wins: 18
Number of previous best player wins: 14
Number of ties: 18
Trained player win percentage:  0.5625
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 645.0288581848145 and Testing Loss: 202.36606407165527
Epoch:  1
Training Loss: 614.7088346481323 and Testing Loss: 165.42940855026245
Epoch:  2
Training Loss: 606.8118047714233 and Testing Loss: 178.9478588104248
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 18 with time threshold: 0.45

Number of trained player wins: 14
Number of previous best player wins: 13
Number of ties: 23
Trained player win percentage:  0.5185185185185185
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 616.2976713180542 and Testing Loss: 190.47827339172363
Epoch:  1
Training Loss: 644.604211807251 and Testing Loss: 171.3258762359619
Epoch:  2
Training Loss: 617.4315071105957 and Testing Loss: 150.29085731506348
Epoch:  3
Training Loss: 597.8837537765503 and Testing Loss: 171.53334426879883
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 19 with time threshold: 0.45

Number of trained player wins: 29
Number of previous best player wins: 16
Number of ties: 5
Trained player win percentage:  0.6444444444444445
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 629.7597379684448 and Testing Loss: 191.26271629333496
Epoch:  1
Training Loss: 632.1936464309692 and Testing Loss: 179.61586570739746
Epoch:  2
Training Loss: 622.8410587310791 and Testing Loss: 165.64501762390137
Epoch:  3
Training Loss: 617.4331617355347 and Testing Loss: 175.92818450927734
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 20 with time threshold: 0.45

Number of trained player wins: 6
Number of previous best player wins: 9
Number of ties: 35
Trained player win percentage:  0.4
Using the previous best player.

Comparing performance to older player at index:  0

Number of trained player wins: 9
Number of previous best player wins: 31
Number of ties: 10
Trained player win percentage:  0.225

Comparing performance to older player at index:  1

Number of trained player wins: 24
Number of previous best player wins: 7
Number of ties: 19
Trained player win percentage:  0.7741935483870968

Comparing performance to Pure MCTS

Number of trained player wins: 4
Number of previous best player wins: 22
Number of ties: 24
Trained player win percentage:  0.15384615384615385

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 666.2144870758057 and Testing Loss: 168.6081829071045
Epoch:  1
Training Loss: 641.2177886962891 and Testing Loss: 155.0851821899414
Epoch:  2
Training Loss: 624.8390130996704 and Testing Loss: 191.06037521362305
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 21 with time threshold: 0.4

Number of trained player wins: 5
Number of previous best player wins: 12
Number of ties: 33
Trained player win percentage:  0.29411764705882354
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 663.66321849823 and Testing Loss: 202.01100540161133
Epoch:  1
Training Loss: 608.574209690094 and Testing Loss: 191.41701126098633
Epoch:  2
Training Loss: 571.117582321167 and Testing Loss: 175.48831367492676
Epoch:  3
Training Loss: 565.1963777542114 and Testing Loss: 175.66828632354736
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 22 with time threshold: 0.4

Number of trained player wins: 8
Number of previous best player wins: 9
Number of ties: 33
Trained player win percentage:  0.47058823529411764
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 670.7247829437256 and Testing Loss: 166.78534698486328
Epoch:  1
Training Loss: 610.1938371658325 and Testing Loss: 155.6211166381836
Epoch:  2
Training Loss: 573.3813829421997 and Testing Loss: 161.5730686187744
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 23 with time threshold: 0.4

Number of trained player wins: 10
Number of previous best player wins: 11
Number of ties: 29
Trained player win percentage:  0.47619047619047616
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 688.7969245910645 and Testing Loss: 140.4665927886963
Epoch:  1
Training Loss: 625.9462099075317 and Testing Loss: 139.33598232269287
Epoch:  2
Training Loss: 589.4173936843872 and Testing Loss: 112.66987133026123
Epoch:  3
Training Loss: 582.0979433059692 and Testing Loss: 111.49313831329346
Epoch:  4
Training Loss: 578.1401662826538 and Testing Loss: 119.90812873840332
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 24 with time threshold: 0.4

Number of trained player wins: 8
Number of previous best player wins: 16
Number of ties: 26
Trained player win percentage:  0.3333333333333333
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 702.2915306091309 and Testing Loss: 134.74910306930542
Epoch:  1
Training Loss: 639.625940322876 and Testing Loss: 141.98898029327393
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 25 with time threshold: 0.4

Number of trained player wins: 10
Number of previous best player wins: 19
Number of ties: 21
Trained player win percentage:  0.3448275862068966
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 636.2539987564087 and Testing Loss: 216.75522804260254
Epoch:  1
Training Loss: 580.8634824752808 and Testing Loss: 185.34916973114014
Epoch:  2
Training Loss: 541.5978441238403 and Testing Loss: 180.5264105796814
Epoch:  3
Training Loss: 534.5072050094604 and Testing Loss: 186.91140747070312
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 26 with time threshold: 0.4

Number of trained player wins: 17
Number of previous best player wins: 7
Number of ties: 26
Trained player win percentage:  0.7083333333333334
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 540.9959902763367 and Testing Loss: 190.4137372970581
Epoch:  1
Training Loss: 532.3945579528809 and Testing Loss: 216.59622764587402
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 27 with time threshold: 0.4

Number of trained player wins: 5
Number of previous best player wins: 6
Number of ties: 39
Trained player win percentage:  0.45454545454545453
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 577.9978513717651 and Testing Loss: 140.01996040344238
Epoch:  1
Training Loss: 573.218014717102 and Testing Loss: 147.18782806396484
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 28 with time threshold: 0.4

Number of trained player wins: 3
Number of previous best player wins: 8
Number of ties: 39
Trained player win percentage:  0.2727272727272727
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 569.7959260940552 and Testing Loss: 132.02280807495117
Epoch:  1
Training Loss: 570.9663982391357 and Testing Loss: 141.79408073425293
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 29 with time threshold: 0.4

Number of trained player wins: 2
Number of previous best player wins: 3
Number of ties: 45
Trained player win percentage:  0.4
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 572.9564170837402 and Testing Loss: 133.28386783599854
Epoch:  1
Training Loss: 573.8111915588379 and Testing Loss: 130.614972114563
Epoch:  2
Training Loss: 539.4975891113281 and Testing Loss: 101.15812158584595
Epoch:  3
Training Loss: 485.9196300506592 and Testing Loss: 97.13397169113159
Epoch:  4
Training Loss: 474.8103041648865 and Testing Loss: 115.77467489242554
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 30 with time threshold: 0.4

Number of trained player wins: 0
Number of previous best player wins: 18
Number of ties: 32
Trained player win percentage:  0.0
Using the previous best player.

Comparing performance to older player at index:  0

Number of trained player wins: 22
Number of previous best player wins: 2
Number of ties: 26
Trained player win percentage:  0.9166666666666666

Comparing performance to older player at index:  1

Number of trained player wins: 12
Number of previous best player wins: 16
Number of ties: 22
Trained player win percentage:  0.42857142857142855

Comparing performance to older player at index:  2

Number of trained player wins: 14
Number of previous best player wins: 9
Number of ties: 27
Trained player win percentage:  0.6086956521739131

Comparing performance to Pure MCTS

Number of trained player wins: 8
Number of previous best player wins: 10
Number of ties: 32
Trained player win percentage:  0.4444444444444444

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 529.8525524139404 and Testing Loss: 168.79437637329102
Epoch:  1
Training Loss: 533.2924995422363 and Testing Loss: 153.67780876159668
Epoch:  2
Training Loss: 497.72546339035034 and Testing Loss: 134.5059633255005
Epoch:  3
Training Loss: 442.7759337425232 and Testing Loss: 129.86749267578125
Epoch:  4
Training Loss: 434.8804187774658 and Testing Loss: 120.123779296875

Evaluating players at checkpoint: 31 with time threshold: 0.35000000000000003

Number of trained player wins: 1
Number of previous best player wins: 8
Number of ties: 41
Trained player win percentage:  0.1111111111111111
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 520.5510139465332 and Testing Loss: 174.5502815246582
Epoch:  1
Training Loss: 522.4288816452026 and Testing Loss: 157.81685638427734
Epoch:  2
Training Loss: 491.2702708244324 and Testing Loss: 134.7832145690918
Epoch:  3
Training Loss: 443.9303913116455 and Testing Loss: 128.13482475280762
Epoch:  4
Training Loss: 436.21146392822266 and Testing Loss: 129.16880893707275
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 32 with time threshold: 0.35000000000000003

Number of trained player wins: 15
Number of previous best player wins: 21
Number of ties: 14
Trained player win percentage:  0.4166666666666667
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 533.3004560470581 and Testing Loss: 158.70499992370605
Epoch:  1
Training Loss: 534.6788744926453 and Testing Loss: 144.0868968963623
Epoch:  2
Training Loss: 501.54254055023193 and Testing Loss: 153.45178413391113
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 33 with time threshold: 0.35000000000000003

Number of trained player wins: 12
Number of previous best player wins: 13
Number of ties: 25
Trained player win percentage:  0.48
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 523.9083003997803 and Testing Loss: 173.37801933288574
Epoch:  1
Training Loss: 524.969841003418 and Testing Loss: 169.00016975402832
Epoch:  2
Training Loss: 497.2613458633423 and Testing Loss: 142.93289041519165
Epoch:  3
Training Loss: 451.1049041748047 and Testing Loss: 130.73724269866943
Epoch:  4
Training Loss: 441.01929092407227 and Testing Loss: 127.26826572418213

Evaluating players at checkpoint: 34 with time threshold: 0.35000000000000003

Number of trained player wins: 10
Number of previous best player wins: 13
Number of ties: 27
Trained player win percentage:  0.43478260869565216
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 553.4305992126465 and Testing Loss: 121.93137788772583
Epoch:  1
Training Loss: 554.5307178497314 and Testing Loss: 129.8923683166504
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 35 with time threshold: 0.35000000000000003

Number of trained player wins: 5
Number of previous best player wins: 4
Number of ties: 41
Trained player win percentage:  0.5555555555555556
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 504.82266998291016 and Testing Loss: 147.1562032699585
Epoch:  1
Training Loss: 542.3986196517944 and Testing Loss: 154.93404293060303
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 36 with time threshold: 0.35000000000000003

Number of trained player wins: 6
Number of previous best player wins: 5
Number of ties: 39
Trained player win percentage:  0.5454545454545454
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 511.4135456085205 and Testing Loss: 143.88348960876465
Epoch:  1
Training Loss: 553.4524488449097 and Testing Loss: 139.39102745056152
Epoch:  2
Training Loss: 513.453028678894 and Testing Loss: 140.22806358337402
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 37 with time threshold: 0.35000000000000003

Number of trained player wins: 5
Number of previous best player wins: 8
Number of ties: 37
Trained player win percentage:  0.38461538461538464
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 496.387806892395 and Testing Loss: 183.1500062942505
Epoch:  1
Training Loss: 531.6420593261719 and Testing Loss: 188.63995552062988
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 38 with time threshold: 0.35000000000000003

Number of trained player wins: 12
Number of previous best player wins: 15
Number of ties: 23
Trained player win percentage:  0.4444444444444444
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 541.150520324707 and Testing Loss: 121.48996448516846
Epoch:  1
Training Loss: 584.6349411010742 and Testing Loss: 118.30500984191895
Epoch:  2
Training Loss: 532.7962436676025 and Testing Loss: 95.12172079086304
Epoch:  3
Training Loss: 486.6447916030884 and Testing Loss: 92.147864818573
Epoch:  4
Training Loss: 478.7034339904785 and Testing Loss: 98.87789916992188
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 39 with time threshold: 0.35000000000000003

Number of trained player wins: 1
Number of previous best player wins: 10
Number of ties: 39
Trained player win percentage:  0.09090909090909091
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 490.84609031677246 and Testing Loss: 180.85662269592285
Epoch:  1
Training Loss: 526.8370656967163 and Testing Loss: 165.86930418014526
Epoch:  2
Training Loss: 487.0664300918579 and Testing Loss: 152.0413942337036
Epoch:  3
Training Loss: 443.3049011230469 and Testing Loss: 139.0649356842041
Epoch:  4
Training Loss: 435.19237422943115 and Testing Loss: 146.9745216369629
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 40 with time threshold: 0.35000000000000003

Number of trained player wins: 0
Number of previous best player wins: 11
Number of ties: 39
Trained player win percentage:  0.0
Using the previous best player.

Comparing performance to older player at index:  0

Number of trained player wins: 23
Number of previous best player wins: 0
Number of ties: 27
Trained player win percentage:  1.0

Comparing performance to older player at index:  1

Number of trained player wins: 13
Number of previous best player wins: 13
Number of ties: 24
Trained player win percentage:  0.5

Comparing performance to older player at index:  2

Number of trained player wins: 15
Number of previous best player wins: 13
Number of ties: 22
Trained player win percentage:  0.5357142857142857

Comparing performance to older player at index:  3

Number of trained player wins: 6
Number of previous best player wins: 4
Number of ties: 40
Trained player win percentage:  0.6

Comparing performance to Pure MCTS

Number of trained player wins: 6
Number of previous best player wins: 8
Number of ties: 36
Trained player win percentage:  0.42857142857142855

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 488.2323522567749 and Testing Loss: 164.73314666748047
Epoch:  1
Training Loss: 526.5900497436523 and Testing Loss: 157.81493377685547
Epoch:  2
Training Loss: 485.27122592926025 and Testing Loss: 127.53632497787476
Epoch:  3
Training Loss: 445.87112760543823 and Testing Loss: 122.66641044616699
Epoch:  4
Training Loss: 438.13047218322754 and Testing Loss: 130.01745176315308
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 41 with time threshold: 0.30000000000000004

Number of trained player wins: 6
Number of previous best player wins: 5
Number of ties: 39
Trained player win percentage:  0.5454545454545454
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 452.11137676239014 and Testing Loss: 169.44506454467773
Epoch:  1
Training Loss: 488.2572555541992 and Testing Loss: 175.0580358505249
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 42 with time threshold: 0.30000000000000004

Number of trained player wins: 4
Number of previous best player wins: 6
Number of ties: 40
Trained player win percentage:  0.4
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 442.75515365600586 and Testing Loss: 160.96072959899902
Epoch:  1
Training Loss: 477.61170864105225 and Testing Loss: 158.13371753692627
Epoch:  2
Training Loss: 437.683500289917 and Testing Loss: 146.27212047576904
Epoch:  3
Training Loss: 396.8616223335266 and Testing Loss: 135.89082527160645
Epoch:  4
Training Loss: 389.23408603668213 and Testing Loss: 139.87195491790771
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 43 with time threshold: 0.30000000000000004

Number of trained player wins: 0
Number of previous best player wins: 12
Number of ties: 38
Trained player win percentage:  0.0
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 457.348876953125 and Testing Loss: 143.8167848587036
Epoch:  1
Training Loss: 494.7679796218872 and Testing Loss: 128.1392502784729
Epoch:  2
Training Loss: 457.72639560699463 and Testing Loss: 114.1012544631958
Epoch:  3
Training Loss: 416.6393971443176 and Testing Loss: 111.06262016296387
Epoch:  4
Training Loss: 409.3181347846985 and Testing Loss: 117.27481746673584
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 44 with time threshold: 0.30000000000000004

Number of trained player wins: 0
Number of previous best player wins: 12
Number of ties: 38
Trained player win percentage:  0.0
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 473.6449975967407 and Testing Loss: 132.60480976104736
Epoch:  1
Training Loss: 508.61088943481445 and Testing Loss: 127.69565773010254
Epoch:  2
Training Loss: 472.00476264953613 and Testing Loss: 102.40938997268677
Epoch:  3
Training Loss: 433.8600797653198 and Testing Loss: 108.69220161437988
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 45 with time threshold: 0.30000000000000004

Number of trained player wins: 4
Number of previous best player wins: 2
Number of ties: 44
Trained player win percentage:  0.6666666666666666
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 454.7004437446594 and Testing Loss: 99.6355938911438
Epoch:  1
Training Loss: 460.0897922515869 and Testing Loss: 86.77447986602783
Epoch:  2
Training Loss: 449.65514612197876 and Testing Loss: 86.44130229949951
Epoch:  3
Training Loss: 445.15742015838623 and Testing Loss: 77.8637022972107
Epoch:  4
Training Loss: 441.9160237312317 and Testing Loss: 78.43451070785522
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 46 with time threshold: 0.30000000000000004

Number of trained player wins: 5
Number of previous best player wins: 6
Number of ties: 39
Trained player win percentage:  0.45454545454545453
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 402.75040435791016 and Testing Loss: 123.50501251220703
Epoch:  1
Training Loss: 404.7690849304199 and Testing Loss: 119.24602317810059
Epoch:  2
Training Loss: 395.3754663467407 and Testing Loss: 132.1828384399414
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 47 with time threshold: 0.30000000000000004

Number of trained player wins: 9
Number of previous best player wins: 1
Number of ties: 40
Trained player win percentage:  0.9
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 373.6241068840027 and Testing Loss: 134.7103977203369
Epoch:  1
Training Loss: 373.85637950897217 and Testing Loss: 143.4842405319214
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 48 with time threshold: 0.30000000000000004

Number of trained player wins: 0
Number of previous best player wins: 2
Number of ties: 48
Trained player win percentage:  0.0
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 388.1467294692993 and Testing Loss: 111.95980882644653
Epoch:  1
Training Loss: 388.74592304229736 and Testing Loss: 116.85580921173096
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 49 with time threshold: 0.30000000000000004

Number of trained player wins: 0
Number of previous best player wins: 3
Number of ties: 47
Trained player win percentage:  0.0
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 404.6301155090332 and Testing Loss: 128.7857928276062
Epoch:  1
Training Loss: 404.093101978302 and Testing Loss: 95.48236322402954
Epoch:  2
Training Loss: 396.26501417160034 and Testing Loss: 94.95428276062012
Epoch:  3
Training Loss: 391.741961479187 and Testing Loss: 101.66057348251343
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 50 with time threshold: 0.30000000000000004

Number of trained player wins: 1
Number of previous best player wins: 0
Number of ties: 49
Trained player win percentage:  1.0
Using the trained player.

Comparing performance to older player at index:  0

Number of trained player wins: 1
Number of previous best player wins: 25
Number of ties: 24
Trained player win percentage:  0.038461538461538464

Comparing performance to older player at index:  1

Number of trained player wins: 0
Number of previous best player wins: 10
Number of ties: 40
Trained player win percentage:  0.0

Comparing performance to older player at index:  2

Number of trained player wins: 0
Number of previous best player wins: 16
Number of ties: 34
Trained player win percentage:  0.0

Comparing performance to older player at index:  3

Number of trained player wins: 28
Number of previous best player wins: 12
Number of ties: 10
Trained player win percentage:  0.7

Comparing performance to older player at index:  4

Number of trained player wins: 25
Number of previous best player wins: 6
Number of ties: 19
Trained player win percentage:  0.8064516129032258

Comparing performance to Pure MCTS

Number of trained player wins: 0
Number of previous best player wins: 18
Number of ties: 32
Trained player win percentage:  0.0

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 413.0619616508484 and Testing Loss: 71.36162519454956
Epoch:  1
Training Loss: 418.2012267112732 and Testing Loss: 76.8993353843689
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 51 with time threshold: 0.25000000000000006

Number of trained player wins: 0
Number of previous best player wins: 0
Number of ties: 50
All ties, using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 376.3963580131531 and Testing Loss: 103.79060888290405
Epoch:  1
Training Loss: 384.2860269546509 and Testing Loss: 102.66881370544434
Epoch:  2
Training Loss: 357.74964904785156 and Testing Loss: 98.87232398986816
Epoch:  3
Training Loss: 349.8747515678406 and Testing Loss: 90.47570252418518
Epoch:  4
Training Loss: 347.21441650390625 and Testing Loss: 115.20083093643188
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 52 with time threshold: 0.25000000000000006

Number of trained player wins: 0
Number of previous best player wins: 0
Number of ties: 50
All ties, using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 360.5324811935425 and Testing Loss: 127.95291137695312
Epoch:  1
Training Loss: 368.3729519844055 and Testing Loss: 98.44941759109497
Epoch:  2
Training Loss: 335.7360556125641 and Testing Loss: 117.3620662689209
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 53 with time threshold: 0.25000000000000006

Number of trained player wins: 1
Number of previous best player wins: 0
Number of ties: 49
Trained player win percentage:  1.0
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 366.48554039001465 and Testing Loss: 115.24946975708008
Epoch:  1
Training Loss: 368.834228515625 and Testing Loss: 102.834641456604
Epoch:  2
Training Loss: 361.59998846054077 and Testing Loss: 101.90637493133545
Epoch:  3
Training Loss: 359.247540473938 and Testing Loss: 99.90184354782104
Epoch:  4
Training Loss: 355.70584630966187 and Testing Loss: 91.63148307800293

Evaluating players at checkpoint: 54 with time threshold: 0.25000000000000006

Number of trained player wins: 0
Number of previous best player wins: 0
Number of ties: 50
All ties, using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 396.4078674316406 and Testing Loss: 94.47799968719482
Epoch:  1
Training Loss: 393.0427289009094 and Testing Loss: 103.0149474143982
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 55 with time threshold: 0.25000000000000006

Number of trained player wins: 0
Number of previous best player wins: 36
Number of ties: 14
Trained player win percentage:  0.0
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 401.2527599334717 and Testing Loss: 103.64116191864014
Epoch:  1
Training Loss: 393.0967130661011 and Testing Loss: 84.68935060501099
Epoch:  2
Training Loss: 361.4543743133545 and Testing Loss: 89.32989597320557
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 56 with time threshold: 0.25000000000000006

Number of trained player wins: 0
Number of previous best player wins: 26
Number of ties: 24
Trained player win percentage:  0.0
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 377.99842166900635 and Testing Loss: 118.66661405563354
Epoch:  1
Training Loss: 371.4978790283203 and Testing Loss: 118.82164764404297
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 57 with time threshold: 0.25000000000000006

Number of trained player wins: 0
Number of previous best player wins: 30
Number of ties: 20
Trained player win percentage:  0.0
Using the previous best player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 371.4654059410095 and Testing Loss: 126.2230634689331
Epoch:  1
Training Loss: 362.87913370132446 and Testing Loss: 119.38484287261963
Epoch:  2
Training Loss: 332.96905040740967 and Testing Loss: 116.85166072845459
Epoch:  3
Training Loss: 328.3022131919861 and Testing Loss: 122.77982997894287
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 58 with time threshold: 0.25000000000000006

Number of trained player wins: 25
Number of previous best player wins: 0
Number of ties: 25
Trained player win percentage:  1.0
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 424.0529136657715 and Testing Loss: 111.23015451431274
Epoch:  1
Training Loss: 421.6252088546753 and Testing Loss: 108.39660024642944
Epoch:  2
Training Loss: 414.62752056121826 and Testing Loss: 123.20078325271606
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 59 with time threshold: 0.25000000000000006

Number of trained player wins: 36
Number of previous best player wins: 9
Number of ties: 5
Trained player win percentage:  0.8
Using the trained player.

Running simulations. . .
Number of moves available for training:  800
Number of moves available for testing:  200

Training. . .
Epoch:  0
Training Loss: 457.4925146102905 and Testing Loss: 122.52434253692627
Epoch:  1
Training Loss: 460.6564197540283 and Testing Loss: 117.81809616088867
Epoch:  2
Training Loss: 449.49086570739746 and Testing Loss: 115.50103950500488
Epoch:  3
Training Loss: 445.59868717193604 and Testing Loss: 121.97679805755615
Testing loss increasing, using model from one iteration earlier.

Evaluating players at checkpoint: 60 with time threshold: 0.25000000000000006

Number of trained player wins: 16
Number of previous best player wins: 9
Number of ties: 25
Trained player win percentage:  0.64
Using the trained player.

Comparing performance to older player at index:  0

Number of trained player wins: 3
Number of previous best player wins: 25
Number of ties: 22
Trained player win percentage:  0.10714285714285714

Comparing performance to older player at index:  1

Number of trained player wins: 12
Number of previous best player wins: 19
Number of ties: 19
Trained player win percentage:  0.3870967741935484

Comparing performance to older player at index:  2

Number of trained player wins: 10
Number of previous best player wins: 16
Number of ties: 24
Trained player win percentage:  0.38461538461538464

Comparing performance to older player at index:  3

Number of trained player wins: 11
Number of previous best player wins: 16
Number of ties: 23
Trained player win percentage:  0.4074074074074074

Comparing performance to older player at index:  4

Number of trained player wins: 1
Number of previous best player wins: 18
Number of ties: 31
Trained player win percentage:  0.05263157894736842

Comparing performance to older player at index:  5

Number of trained player wins: 3
Number of previous best player wins: 0
Number of ties: 47
Trained player win percentage:  1.0

Comparing performance to Pure MCTS

Number of trained player wins: 0
Number of previous best player wins: 24
Number of ties: 26
Trained player win percentage:  0.0

Running simulations. . .
